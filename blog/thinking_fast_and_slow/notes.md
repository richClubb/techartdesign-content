* Most scientific studies around learning focus on slow deliberate practice, but the focus on AI usage is about how to get things done fast!
* Is this hurting our ability to actually think properly as we're constantly relying on AI to summarise information and possibly losing the nuance of presentation?

Scenario;
Person A writes a bullet point list and asks a chatbot to make it sound "nice" and "professional". Sends it to person B

Person B looks at it, doesn't want to spend the time reading it and asks a chatbot to summarise it. 

(I'm skipping over the fact that Person A could just have given the summary to Person B and that would have saved the energy cost. This is even worse when you consider that it might actually be a 1 to many mapping. Person A might be sending it to 10 people, all of whom use a chatbot to summarise the data, and even worse, depending on the chatbot, or it's 'mood' they might get 10 different outputs. One of which was for chocolate cookies.)

Not only do we have 2 chinese whisper situations if Person A spent the time thinking of how to succintly create the information then they could have presented it in a way that was easy for Person B to digest.

Part of the difficulty is that you present information to people based on their level of understanding. E.g. If I'm discussing issues with an experienced engineer, I'm going to speak to them differently than a junior engineer, similarly, if they have a completely different discipline, I'm going to try to relate to their experiences. I'm not going to go into minute detail if I know that someone isn't interested.

Not all information is going to be useful to all people, you've got to think who you're talking to. Do you need to tell them, 

Maybe that is the use for the LLM, but it's still a lot of work for the first person. To do it well, you have to write it well the first time. Then get the chatbot to re-present it, then review it with that hat on, and so on and so on.....
